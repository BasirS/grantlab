# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama3.1:8b

# Embedding Model
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Vector Database
VECTOR_DB_TYPE=chroma
CHROMA_PERSIST_DIR=./data/chroma_db

# Optional: Cloud API fallbacks (keep empty for local-only mode)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Application Settings
MAX_CHUNK_SIZE=512
CHUNK_OVERLAP=50
TOP_K_RETRIEVAL=5

# Grant Discovery Settings
MAX_SEARCH_RESULTS=20
SCRAPING_DELAY=2